# -*- coding: utf-8 -*-
"""IRIS_Data_Cleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fshuMH5crI_jKAwaRe2yvt2tMvn6FKlW
"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Load the Iris dataset
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'
column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']
df = pd.read_csv(url, header=None, names=column_names)

df.head()

df.isnull().sum()

# Select the features to normalize
features_to_normalize = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]

# Normalize using Min-Max Scaling
scaler = MinMaxScaler()
normalized_features = scaler.fit_transform(features_to_normalize)

# Update the DataFrame with normalized values
df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']] = normalized_features

# Check the result
df.head()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['class'] = le.fit_transform(df['class'])

df.head()

from google.colab import drive
drive.mount('/content/drive')

# Save the cleaned data to a CSV file

#/content/drive/MyDrive/AI BootCamp
df.to_csv('/content/drive/MyDrive/AI BootCamp/cleaned_iris_data.csv', index=False)